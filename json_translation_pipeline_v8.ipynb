{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Steps\n",
        "1. Set Translation Language\n",
        "2. upload one json to translate\n",
        "3. run all cells\n",
        "4. download your translation\n",
        "\n",
        "\n",
        "# TODO:\n",
        "##Fancier version will:\n",
        "1. process any number of files\n",
        "2. connect open-ai\n",
        "3. connect gguf\n",
        "4. remove any \\u00e8 type characters\n",
        "\n",
        "\n",
        "...\n",
        "\n",
        "for writeup:\n",
        "discuss balance of system-1 and system -2\n",
        "remove any \\u00e8 type characters\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vt9mx8Iyh392"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_language = \"italian\""
      ],
      "metadata": {
        "id": "XB5LM1Oqh6U8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "json translator tool\n",
        "auto-translate the 'value' fields in a json\n",
        "\n",
        "Steps:\n",
        "\n",
        "initial input:\n",
        "(\"translate_this_json\" = 'JSON TEXT',\n",
        "\"translate_into_this_language\" = 'NAME OF LANGUAGE')\n",
        "\n",
        "Save original json:\n",
        "\t-> original_translate_this_json\n",
        "\n",
        "Save draft of final json:\n",
        "keys from translate_this_json ->\n",
        "\t-> final_translated_json_draft with empty string values\n",
        "\n",
        "Map Json key structure/format:\n",
        "\t-> required_json_key_format\n",
        "\n",
        "Make master dictionary of lists of translations:\n",
        "- convert to python dict ->  dict_of_lists_of_translations\n",
        "\n",
        "X times, batch translation of json:\n",
        "- translation: translate original_translate_this_json values\n",
        "   -> translate_into_this_language\n",
        "   (translate the whole json in one batch\n",
        "- confirm JSON structure of output\n",
        "  (if not correct SON structure, loop back repeat translation\n",
        "- store each in dict_of_lists_of_translations\n",
        "\n",
        "Rank Quality of Translations:\n",
        "\t- rank each a list in dict_of_lists_of_translations\n",
        "\n",
        "\t- make a ranked list\n",
        "\t- pick the first one\n",
        "\t- store in final_translated_json_draft\n",
        "\n",
        "Make Final Translation\n",
        "final_translated_json = final_translated_json_draft\n",
        "\n",
        "Output\n",
        "output_body = {\n",
        "'translate_this_json': translate_this_json\n",
        "'dict_of_lists_of_translations': dict_of_lists_of_translations\n",
        "'final_translated_json_draft': final_translated_json_draft\n",
        "}\n",
        "\n",
        "final output:\n",
        "\treturn output_body\n",
        "\n",
        "\n",
        "Version:\n",
        "1. python script\n",
        "2. endpoint\n",
        "3. using api-model service (online)\n",
        "4. using local .GGUF model (offline)\n",
        "\t- make:\n",
        "\t\tA. raw llama.cpp wrapper\n",
        "\t\tB. call_api for python-lamma-cpp\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LM_DR6LHwiGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        ".env: get your environment variables:\n",
        "  Using the Google Secretes (like.env) system\n",
        "  built into colab on the left menu: the 'key' icon.\n",
        "\"\"\"\n",
        "from google.colab import userdata\n",
        "mistral_api_key = userdata.get('mistral_api_key')\n",
        "# mistral_api_key = 'xxx'"
      ],
      "metadata": {
        "id": "e3867oYRWycv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select Model\n",
        "\n",
        "\n",
        "\n",
        "######################\n",
        "# Mixtral 8x7 \"Small\"\n",
        "######################\n",
        "use_this_model = \"mistral-small\"\n",
        "\n",
        "######################\n",
        "# Mixtral Large ???\n",
        "######################\n",
        "use_this_model = \"mistral-large-latest\"\n",
        "\n",
        "####################\n",
        "# Mistral 7b \"Tiny\"\n",
        "####################\n",
        "use_this_model = \"mistral-tiny\""
      ],
      "metadata": {
        "id": "a0RNDTgOVGvy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# make a list of json files"
      ],
      "metadata": {
        "id": "P-DcHvpKxLoA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eW2HxELNwgEM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def list_json_files_in_cwd():\n",
        "    \"\"\"\n",
        "    Returns a list of .json files in the current working directory.\n",
        "    \"\"\"\n",
        "    # List all files in the current working directory\n",
        "    files_in_cwd = os.listdir('.')\n",
        "\n",
        "    # Filter the list to include only .json files\n",
        "    json_files = [file for file in files_in_cwd if file.endswith('.json')]\n",
        "\n",
        "    return json_files\n",
        "\n",
        "# Example usage\n",
        "json_files_list = list_json_files_in_cwd()\n",
        "print(\"JSON files in the CWD:\", json_files_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process Json\n",
        "- make a model/skeleton template"
      ],
      "metadata": {
        "id": "Kiua0xCTwj3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def load_json_file(file_path):\n",
        "    \"\"\"\n",
        "    Loads and reads a JSON file, returning its content as a Python dictionary.\n",
        "\n",
        "    :param file_path: Path to the .json file to be read.\n",
        "    :return: A dictionary containing the data from the JSON file.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    return data\n",
        "\n",
        "def create_deep_empty_structure(data):\n",
        "    \"\"\"\n",
        "    Recursively creates a deep copy of the provided data structure,\n",
        "    replacing all terminal values with empty lists, and maintaining the same structure.\n",
        "\n",
        "    :param data: The original data structure, potentially containing nested dictionaries.\n",
        "    :return: A new data structure with the same keys but with empty lists as terminal values.\n",
        "    \"\"\"\n",
        "    if isinstance(data, dict):  # Checks if the current data item is a dictionary\n",
        "        return {key: create_deep_empty_structure(value) for key, value in data.items()}\n",
        "    else:\n",
        "        return []  # Replaces non-dictionary values with an empty list\n",
        "\n",
        "def create_empty_json_file(original_data, new_file_path):\n",
        "    \"\"\"\n",
        "    Creates a new JSON file replicating the structure of the original data,\n",
        "    but with empty lists for all terminal values.\n",
        "\n",
        "    :param original_data: Dictionary containing the original data.\n",
        "    :param new_file_path: Path for the new .json file to be created.\n",
        "    \"\"\"\n",
        "    # Create a new structure with the same keys but with empty lists as terminal values\n",
        "    empty_data = create_deep_empty_structure(original_data)\n",
        "\n",
        "    # Write this new structure to a new JSON file\n",
        "    with open(new_file_path, 'w') as file:\n",
        "        json.dump(empty_data, file, indent=4)\n",
        "\n",
        "    return empty_data\n",
        "\n",
        "# Assuming 'json_files_list' is defined and contains paths to your JSON files\n",
        "# Example usage\n",
        "original_file_path = json_files_list[0]  # Path to the original JSON file\n",
        "new_file_path = 'new_empty_lists.json'  # Path for the new JSON file\n",
        "\n",
        "# Load the original JSON file\n",
        "original_data = load_json_file(original_file_path)\n",
        "\n",
        "# Create a new JSON file with the deep empty structure\n",
        "skeleton_json = create_empty_json_file(original_data, new_file_path)\n",
        "print(f\"New JSON file created at: {new_file_path}\")\n",
        "print(f\"New skeleton_json: {skeleton_json}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W6EO15mYMyrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# put translation into list_skeleton_json"
      ],
      "metadata": {
        "id": "H2TCjk9vTYuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_skeleton_json_with_data(skeleton_json, source_data):\n",
        "    \"\"\"\n",
        "    Recursively fills the skeleton_json structure with data from the source_data.\n",
        "\n",
        "    :param skeleton_json: The skeleton_json structure with empty lists as terminal values.\n",
        "    :param source_data: The source data structure from which values are to be copied.\n",
        "    :return: The skeleton_json structure filled with values from source_data.\n",
        "    \"\"\"\n",
        "    if isinstance(skeleton_json, dict) and isinstance(source_data, dict):\n",
        "        for key in skeleton_json.keys():\n",
        "            if key in source_data:\n",
        "                skeleton_json[key] = list_skeleton_json_with_data(skeleton_json[key], source_data[key])\n",
        "    elif isinstance(skeleton_json, list) and not skeleton_json:  # Check if skeleton_json is an empty list\n",
        "        return source_data  # Replace the empty list with the source data value\n",
        "    return skeleton_json\n"
      ],
      "metadata": {
        "id": "q4GpG7pYTYRI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## save json utility"
      ],
      "metadata": {
        "id": "4Cd_hOezTZ13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from datetime import datetime as dt\n",
        "\n",
        "def save_json_to_file(input_file, file_path, optional_tag=\"\"):\n",
        "    \"\"\"\n",
        "    Saves a JSON object to a file.\n",
        "\n",
        "    :param data: The JSON object to save.\n",
        "    :param file_path: The path to the JSON file where the object should be saved.\n",
        "    \"\"\"\n",
        "    # with open(file_path, 'w') as file:\n",
        "    #     json.dump(data, file, indent=4)\n",
        "\n",
        "    # make readable time\n",
        "    date_time = dt.utcnow()\n",
        "    clean_timestamp = date_time.strftime('%Y%m%d%H%M%S%f')\n",
        "\n",
        "\n",
        "    new_title = f\"{target_language}_{clean_timestamp}_{file_path}\"\n",
        "\n",
        "    new_title = optional_tag + new_title\n",
        "\n",
        "    with open(new_title, 'w') as outfile:\n",
        "        json.dump(input_file, outfile, indent=4)"
      ],
      "metadata": {
        "id": "zgAkpTp_TaKX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions to call Mistral"
      ],
      "metadata": {
        "id": "sfXI2a-SwkDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "related tools:\n",
        "\n",
        "api throttle_protection\n",
        "api async\n",
        "\n",
        "import requests\n",
        "\"\"\"\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "mistral_api_key = userdata.get('mistral_api_key')\n",
        "\n",
        "# Define the endpoint URL\n",
        "endpoint_url = \"https://api.mistral.ai/v1/chat/completions\"\n",
        "\n",
        "# Set the headers\n",
        "headers = {\n",
        "  \"Content-Type\": \"application/json\",\n",
        "  \"Accept\": \"application/json\",\n",
        "  \"Authorization\": f\"Bearer {mistral_api_key}\"\n",
        "}\n",
        "\n",
        "\"\"\"\n",
        "# mode: [{\"role\": \"user\", \"content\": \"say yes\"}]\n",
        "\n",
        "    # Define the request body\n",
        "    request_body = {\n",
        "      \"model\": \"mistral-small\",\n",
        "      \"messages\": [{\"role\": \"user\", \"content\": user_input}]\n",
        "    }\n",
        "\n",
        "    # Send the request\n",
        "    response = requests.post(endpoint_url, headers=headers, json=request_body)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def add_to_context_history(role, comment):\n",
        "\n",
        "    if role == 'user':\n",
        "        segment = {\"role\": \"user\", \"content\": comment}\n",
        "\n",
        "    elif role == 'assistant':\n",
        "        segment = {\"role\": \"assistant\", \"content\": comment}\n",
        "\n",
        "    elif role == 'system':\n",
        "        segment = {\"role\": \"system\", \"content\": comment}\n",
        "\n",
        "    else:\n",
        "        print(\"add_to_context_history(role, comment)\")\n",
        "        print(role, comment)\n",
        "        print('error')\n",
        "\n",
        "    return segment\n",
        "\n",
        "\n",
        "def prompt_user(user_input, context_history):\n",
        "\n",
        "    context_history.append( add_to_context_history(\"user\", user_input) )\n",
        "\n",
        "    return context_history\n",
        "\n",
        "\n",
        "def one_response_to_user(user_input, context_history, use_this_model):\n",
        "    \"\"\"\n",
        "    Input: context_history\n",
        "    Ouput Tuple: assistant_says, context_history\n",
        "    \"\"\"\n",
        "\n",
        "    # prompt user\n",
        "    context_history = prompt_user(user_input, context_history)\n",
        "\n",
        "    # prompt assistant\n",
        "    response = ask_mistral_tiny(context_history, use_this_model)\n",
        "\n",
        "    return response\n",
        "\n",
        "\n",
        "def ask_mistral_tiny(context_history, use_this_model):\n",
        "    # Define the request body\n",
        "    request_body = {\n",
        "      \"model\": use_this_model,\n",
        "      \"messages\": context_history\n",
        "    }\n",
        "\n",
        "    #################\n",
        "    #################\n",
        "    # Hit the ai api\n",
        "    #################\n",
        "    #################\n",
        "    # Send the request\n",
        "    response = requests.post(endpoint_url, headers=headers, json=request_body)\n",
        "\n",
        "    # Check the response status code\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"Error: {response.status_code} {response.text}\")\n",
        "\n",
        "\n",
        "    # Get the response data\n",
        "    response_data = response.json()\n",
        "\n",
        "    # Print the Mistral response\n",
        "\n",
        "    ##\n",
        "    ##\n",
        "    # Turn this print on to see full return data\n",
        "    ##\n",
        "    ##\n",
        "    \"\"\"\n",
        "    e.g.\n",
        "    {\n",
        "      \"id\": \"635cb8d445ujhe5546bb64e5e7\",\n",
        "      \"object\": \"chat.completion\",\n",
        "      \"created\": 170hrjfjf7084,\n",
        "      \"model\": \"mistral-tiny\",\n",
        "      \"choices\": [\n",
        "        {\n",
        "          \"index\": 0,\n",
        "          \"message\": {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": \"Enjoy your cup of tea!\"\n",
        "          },\n",
        "          \"finish_reason\": \"stop\",\n",
        "          \"logprobs\": null\n",
        "        }\n",
        "      ],\n",
        "      \"usage\": {\n",
        "        \"prompt_tokens\": 575,\n",
        "        \"total_tokens\": 629,\n",
        "        \"completion_tokens\": 54\n",
        "      }\n",
        "    }\n",
        "    \"\"\"\n",
        "    # print(json.dumps(response_data, indent=2))\n",
        "    # print(type(response_data))\n",
        "\n",
        "    output = response_data\n",
        "    # print(type(output))\n",
        "    # print(type(output[\"choices\"][0]))\n",
        "\n",
        "    # extract just the 'what they said' part out\n",
        "    assistant_says = output[\"choices\"][0]['message']['content']\n",
        "\n",
        "\n",
        "    return assistant_says\n"
      ],
      "metadata": {
        "id": "6VwJluUZpec0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reset context history (input to ai)"
      ],
      "metadata": {
        "id": "E_fpqzGbmkCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# conversation-history setup\n",
        "context_history = []"
      ],
      "metadata": {
        "id": "1S2qfVYiWLlx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add System instructions for rules"
      ],
      "metadata": {
        "id": "Z3uZBC1MmU3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################\n",
        "# System Prompt\n",
        "################\n",
        "\n",
        "example_1 = {\n",
        "\"Form_One\": {\n",
        "\"FirstName\":\"*First Name*\",\n",
        "\"LastName\":\"*Last Name*\",\n",
        "\"Email\":\"*Email*\",}\n",
        "}\n",
        "example_2 = {\n",
        "\"Form_One\": {\n",
        "\"FirstName\":\"TRANSLATED_First_Name\",\n",
        "\"LastName\":\"TRANSLATED_Last Name\",\n",
        "\"Email\":\"TRANSLATED_Email\",}\n",
        "}\n",
        "\n",
        "\n",
        "# set translation language and structure of output in system\n",
        "comment = f\"\"\"\n",
        "You are a helpful translator bot that produces high\n",
        "quality professional translations in precise json formats.\n",
        "\n",
        "You only translate the leaf values or terminal values in the json.\n",
        "e.g. If the original json says:\n",
        "{example_1}\n",
        "Only translate the final leaf values, NOT the keys above!\n",
        "{example_2}\n",
        "\n",
        "You only translate into {target_language}.\n",
        "You only produce json output in exactly this structure {skeleton_json}.\n",
        "Your translations are clear, accurate, helpful, honrable, brief, polite, and professional.\n",
        "Your do you best to tranlsate every leaf value field leaving nothing blank.\n",
        "\n",
        "You always double check your work and make sure the translation is\n",
        "excellent in the context of the whole body of translation.\n",
        "\"\"\"\n",
        "role = \"system\"\n",
        "\n",
        "context_history.append( add_to_context_history(role, comment) )\n",
        "\n",
        "# print(context_history)"
      ],
      "metadata": {
        "id": "tcO9oDKQPRGw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A-T0zRz0W4uM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add 'user' request for translation"
      ],
      "metadata": {
        "id": "FmBAf4MhmRiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################\n",
        "# User Translation Request\n",
        "###########################\n",
        "\n",
        "# set translation language and structure of output in system\n",
        "comment = f\"\"\"\n",
        "\n",
        "The person we are trying to help needs a json file\n",
        "translated into [{target_language}].\n",
        "Let's help them translate the values in their json file.\n",
        "\n",
        "Carefully translate this original file into {target_language}\n",
        "{original_data}.\n",
        "\n",
        "Double check your work and make sure the translation is\n",
        "accurate, brief, and polite.\n",
        "\n",
        "Make sure your translation is expressed using valid json syntax,\n",
        "as:\n",
        "```json\n",
        "JSON_OBJECT(S)\n",
        "```\n",
        "\n",
        "(e.g. no trailing delimiter, escape conflicting characters, etc).\n",
        "The structure of your translation must fit this structure\n",
        "exactly: {skeleton_json}\n",
        "\"\"\"\n",
        "role = \"user\"\n",
        "\n",
        "context_history.append( add_to_context_history(role, comment) )\n",
        "\n",
        "# print(context_history)"
      ],
      "metadata": {
        "id": "CSLaY7MdSrkn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "########################\n",
        "# Check Json Formatting\n",
        "########################\n",
        "\n",
        "# Helper Function\n",
        "def check_function_description_keys(dict_str, model_dict):\n",
        "    \"\"\"\n",
        "    This function CAN fail and should fail\n",
        "    if the AI needs to retry at a task.\n",
        "    Do not stop server when this this triggers an exception.\n",
        "\n",
        "    edge case: before there is a populated output_log\n",
        "\n",
        "    if passing, this function will return a valid json object\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    Extracts JSON string enclosed between ```json and ``` markers.\n",
        "\n",
        "    Parameters:\n",
        "    - text (str): The input text containing the JSON block.\n",
        "\n",
        "    Returns:\n",
        "    - str: The extracted JSON string, or an empty string if no JSON block is found.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        pattern = r'```json\\n([\\s\\S]*?)\\n```'\n",
        "        match = re.search(pattern, dict_str)\n",
        "        dict_str =  match.group(1) if match else ''\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Dictionary clean failed: {e}\")\n",
        "        return False\n",
        "\n",
        "    # clean\n",
        "    try:\n",
        "        # try safety cleaning\n",
        "        dict_str = dict_str.replace(\"True\", \"true\")\n",
        "        dict_str = dict_str.replace(\"False\", \"false\")\n",
        "        dict_str = dict_str.replace(\"None\", \"null\")\n",
        "\n",
        "        # # This conflicted with free language in description section...\n",
        "        # dict_str = dict_str.replace(\"'\", '\"')\n",
        "\n",
        "        # remove trailing delimiter comma\n",
        "        print(f\"{dict_str[:-6]}\")\n",
        "        dict_str = dict_str.replace('\",\\n}', '\"\\n}')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Dictionary clean failed: {e}\")\n",
        "        return False\n",
        "\n",
        "    # load\n",
        "    try:\n",
        "        # try converting\n",
        "        dict_str = json.loads(dict_str)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Dictionary load failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "    # check if keys are the same\n",
        "    try:\n",
        "        result = dict_str.keys() == model_dict.keys()\n",
        "        if result is False:\n",
        "            print(f\"Failed: keys are not the same.\")\n",
        "            return False\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed with Exception: keys are not the same: {e}\")\n",
        "        return False\n",
        "\n",
        "    # if ok...\n",
        "    return dict_str\n",
        "\n",
        "# # test\n",
        "# dict_str = assistant_says\n",
        "# jsonchecked_translation = check_function_description_keys(dict_str, skeleton_json)"
      ],
      "metadata": {
        "id": "AXvYj09NUelv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check json structure against original"
      ],
      "metadata": {
        "id": "fpQFQqf6mIcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retry_counter = 0\n",
        "json_ok_flag = False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "while not json_ok_flag:\n",
        "    # get a translation\n",
        "    dict_str = ask_mistral_tiny(context_history, use_this_model)\n",
        "\n",
        "    # # check json structure\n",
        "    jsonchecked_translation = check_function_description_keys(dict_str, skeleton_json)\n",
        "\n",
        "    if jsonchecked_translation:\n",
        "        json_ok_flag = True\n",
        "\n",
        "    else:\n",
        "        retry_counter += 1\n",
        "\n",
        "\n",
        "print(f\"retry_counter -> {retry_counter}\")\n",
        "jsonchecked_translation\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "81UT96VTU3Gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save File"
      ],
      "metadata": {
        "id": "viRuuAenmBT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from datetime import datetime as dt\n",
        "\n",
        "# make readable time\n",
        "date_time = dt.utcnow()\n",
        "clean_timestamp = date_time.strftime('%Y%m%d%H%M%S%f')\n",
        "\n",
        "\n",
        "new_title = f\"{target_language}_{clean_timestamp}_{json_files_list[0]}\"\n",
        "\n",
        "with open(new_title, 'w') as outfile:\n",
        "    json.dump(jsonchecked_translation, outfile, indent=4)"
      ],
      "metadata": {
        "id": "ByvGg2XAlHFk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Put Flesh on the Skeleton\n",
        "- add translations to the lists"
      ],
      "metadata": {
        "id": "oxIOt13MTwoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_data = jsonchecked_translation\n",
        "\n",
        "populated_skeleton = list_skeleton_json_with_data(skeleton_json, source_data)\n",
        "\n",
        "populated_skeleton"
      ],
      "metadata": {
        "id": "tAdz3ZPSTwv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_history = []"
      ],
      "metadata": {
        "id": "OTwKMiVEYEwb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################\n",
        "# System Prompt to pick best traslation\n",
        "################\n",
        "\n",
        "example_1 = {\n",
        "\"Form_One\": {\n",
        "\"FirstName\":[],\n",
        "\"LastName\":[],\n",
        "\"Email\":[],}\n",
        "}\n",
        "example_2 = {\n",
        "\"Form_One\": {\n",
        "\"FirstName\":\"TRANSLATED_First_Name\",\n",
        "\"LastName\":\"TRANSLATED_Last Name\",\n",
        "\"Email\":\"TRANSLATED_Email\",}\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# set translation language and structure of output in system\n",
        "comment = f\"\"\"\n",
        "You are a helpful translator bot that selects high\n",
        "quality professional translations from a list and produces or reproduces precise json formats.\n",
        "\n",
        "\n",
        "You select the one best translate in the {target_language}.\n",
        "You only produce json output in exactly this structure {skeleton_json},\n",
        "but with a leaf node text not a list.\n",
        "\n",
        "\n",
        "e.g. The list option json will have this form:\n",
        "{example_1}\n",
        "And your final form must contain one best translation, not a list.\n",
        "{example_2}\n",
        "\n",
        "\n",
        "Your final translation selections are clear, accurate, helpful, honrable, brief, polite, and professional.\n",
        "Your do you best to tranlsate every leaf value field leaving nothing blank.\n",
        "\n",
        "You always double check your work and make sure the translation is\n",
        "excellent in the context of the whole body of translation.\n",
        "\"\"\"\n",
        "role = \"system\"\n",
        "\n",
        "context_history.append( add_to_context_history(role, comment) )\n",
        "\n",
        "# print(context_history)"
      ],
      "metadata": {
        "id": "bTQag4XUUPzB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DJXmKyJ-YLcy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################\n",
        "# User Translation Request to select best translation\n",
        "###########################\n",
        "\n",
        "# set translation language and structure of output in system\n",
        "comment = f\"\"\"\n",
        "\n",
        "The person we are trying to help\n",
        "selecting the best {target_language} language translation for their final translated json file.\n",
        "Let's help them select the best {target_language} language translation leaf node values for their json file.\n",
        "\n",
        "Task to do: Carefully the best {target_language} language translation leaf node values\n",
        "from this list_of_translations json {populated_skeleton}.\n",
        "\n",
        "Double check your work and make sure the translation is\n",
        "accurate, brief, and polite.\n",
        "\n",
        "Make sure your translation is expressed using valid json syntax,\n",
        "as:\n",
        "```json\n",
        "JSON_OBJECT(S)\n",
        "```\n",
        "\n",
        "(e.g. no trailing delimiter, escape conflicting characters, etc).\n",
        "The structure of your translation must fit this structure\n",
        "{skeleton_json} but with a single best translation not a list.\n",
        "\"\"\"\n",
        "role = \"user\"\n",
        "\n",
        "context_history.append( add_to_context_history(role, comment) )\n",
        "\n",
        "# print(context_history)"
      ],
      "metadata": {
        "id": "ZTnBhfEKYLjq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(context_history)"
      ],
      "metadata": {
        "id": "7c3hk1s-YSbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check json structure against original"
      ],
      "metadata": {
        "id": "3Kf7FrSgYLjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retry_counter = 0\n",
        "json_ok_flag = False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "while not json_ok_flag:\n",
        "    # get a translation\n",
        "    dict_str = ask_mistral_tiny(context_history, use_this_model)\n",
        "\n",
        "    # # check json structure\n",
        "    selected_translation_json = check_function_description_keys(dict_str, skeleton_json)\n",
        "\n",
        "    if selected_translation_json:\n",
        "        json_ok_flag = True\n",
        "\n",
        "    else:\n",
        "        retry_counter += 1\n",
        "\n",
        "\n",
        "print(f\"retry_counter -> {retry_counter}\")\n",
        "selected_translation_json\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WMEZBZXoYLjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_translation_json\n"
      ],
      "metadata": {
        "id": "RRHs2BcbZyvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_json_to_file(selected_translation_json, json_files_list[0], \"selected_\")"
      ],
      "metadata": {
        "id": "heUiK_EAaUsS"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}